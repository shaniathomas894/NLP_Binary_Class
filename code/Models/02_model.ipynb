{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8243c9e-164d-49b2-b499-98372343db63",
   "metadata": {},
   "source": [
    "# Model Number 2: Using the Title to Predict the Subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7b8da-d9e2-45e2-afd5-faf9fc5bf108",
   "metadata": {},
   "source": [
    "This model will be using \"Title\" as the features and logistic regression as the model. The EDA suggested there could be some promising results with this feature. At the end of this model, I hope to have a small percentage of misclassifications to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bd1758-13cc-4523-ae59-a843b6950c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a9acaa-a1b9-4a67-ab2a-02e048c6f16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm working on my first UX project about reduc...</td>\n",
       "      <td>Hi, I know this is annoying but this is my fir...</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>1646023113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’m not quite sure what to say for this but I ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>1646021616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self-Sustainable Communities</td>\n",
       "      <td>Over the past few years, I've been learning a ...</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>1646009146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great Barrier Reef: New Huge Coral Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>1645999683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drying Hands: Blow Drying or Paper Towels</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>1645997735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  I'm working on my first UX project about reduc...   \n",
       "1  I’m not quite sure what to say for this but I ...   \n",
       "2                       Self-Sustainable Communities   \n",
       "3           Great Barrier Reef: New Huge Coral Found   \n",
       "4          Drying Hands: Blow Drying or Paper Towels   \n",
       "\n",
       "                                            selftext       subreddit  \\\n",
       "0  Hi, I know this is annoying but this is my fir...  sustainability   \n",
       "1                                                NaN  sustainability   \n",
       "2  Over the past few years, I've been learning a ...  sustainability   \n",
       "3                                                NaN  sustainability   \n",
       "4                                          [removed]  sustainability   \n",
       "\n",
       "   created_utc  \n",
       "0   1646023113  \n",
       "1   1646021616  \n",
       "2   1646009146  \n",
       "3   1645999683  \n",
       "4   1645997735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./data/reddit_content_20220228-063053.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd820bac-e6ff-428d-9a6b-ab25ecf98012",
   "metadata": {},
   "source": [
    "### Quick clean up so the model has 0's and 1's being fed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ffbb35-e92c-4ab0-abfe-edbd7b8497b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].replace({'sustainability':1, 'academia':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d59117-07b3-4f52-9891-42efec180a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['title']\n",
    "y=df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebad3e4-0313-4260-81e8-549c1b4a7bf8",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f175b30d-98c8-4f45-83af-d69ad9754307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.503403\n",
       "1    0.496597\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95cfed-dd79-4d0e-984d-ffc032677098",
   "metadata": {},
   "source": [
    "#### This model would predict every post to be from the academia subreddit and would be correct 50.3% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a0f261a-cfc2-48b5-b7eb-8a4c0e6392ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47254264-21c8-48b6-b280-f8dde02b0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('log', LogisticRegression(random_state=42))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e87f07-01f7-4a16-985d-53249c5147ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3967, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f1ab38-b677-4e82-8550-b2b10a4cce3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9011764705882352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__binary': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__stop_words': 'english',\n",
       " 'log__penalty': 'l2'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#play with different params. trial and error\n",
    "params = {\n",
    "     'cvec__stop_words': [None, 'english'],\n",
    "     'cvec__max_df': [1.0, .75, .5, .25],\n",
    "     'cvec__binary': [True, False],\n",
    "     'log__penalty': ['none', 'l2',],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                  param_grid=params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) # <- cross val score\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c892edfa-209c-424d-bb0b-7aef05de3217",
   "metadata": {},
   "source": [
    "In this grid search, I am using a pipeline consisting of count vectorizing which is counting how many times a word/phrase appears within the corpus and therefore binarizing the words of the corpus, and then running that through a logistic regression model. During the grid search, the model is ran multiple times trying out the different parameters provided for both the count vectorizer and the logistic regression model. Once the grid search is finished, I'm able to see what the best accuracy score was that grid searching produced, and the parameters the grid search found that produced that score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6caef411-dad2-464a-9e11-40ac086cfc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(gs, X_test, y_test, display_labels=['Academia', 'Sustainability'], cmap='cividis', colorbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a80fe-5e49-40a6-8f14-eb72229bdf91",
   "metadata": {},
   "source": [
    "This model has an accuracy score of 90.11%, and struggles in predicting the sustainability subreddit more frequently than it struggles to predict the academia subreddit. With a total of 70 false negatives and 22 false positives where sustainability is the positive class here. This makes for a total of 92 false predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5dedb7-b2cf-498c-a92b-daee52f1cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score = 0.9915966386554622\n",
      "Test Score = 0.907258064516129\n",
      "Cross Val Score = 0.9005042016806722\n",
      "Accuracy Score = 0.907258064516129\n",
      "Recall Score = 0.8580121703853956\n",
      "Precision Score = 0.950561797752809\n",
      "Specificity Score = 0.9559118236472945\n"
     ]
    }
   ],
   "source": [
    "trainscore = gs.score(X_train, y_train)\n",
    "testscore = gs.score(X_test, y_test)\n",
    "crossval = cross_val_score(gs, X_train, y_train).mean()\n",
    "preds = gs.predict(X_test)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, preds).ravel()\n",
    "recall = metrics.recall_score(y_test, preds)\n",
    "precision = metrics.precision_score(y_test, preds)\n",
    "accuracy = testscore\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print (f'Train Score = {trainscore}')\n",
    "print (f'Test Score = {testscore}')\n",
    "print (f'Cross Val Score = {crossval}')\n",
    "print (f'Accuracy Score = {testscore}')\n",
    "print (f'Recall Score = {recall}')\n",
    "print (f'Precision Score = {precision}')\n",
    "print (f'Specificity Score = {specificity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad22c6be-641f-404b-b96e-8b27dec582fa",
   "metadata": {},
   "source": [
    "I see a lot variance between the train, test, and cross val scores which means theres overfitting happening and needs some bias introduced and reduced features. Next step would be to further tune the Grid Search to include less features and hopefully less misclassifications (shown below with a total of 92 misclassifications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1745ccf7-d94e-4575-9b32-7e56ccdff633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sustainability</th>\n",
       "      <td>3.813111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sustainable</th>\n",
       "      <td>3.608215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plastic</th>\n",
       "      <td>2.566082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate</th>\n",
       "      <td>2.346146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbon</th>\n",
       "      <td>2.099366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>1.861947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>1.601500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>1.576961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>1.550937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>environmental</th>\n",
       "      <td>1.521280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "sustainability  3.813111\n",
       "sustainable     3.608215\n",
       "plastic         2.566082\n",
       "climate         2.346146\n",
       "carbon          2.099366\n",
       "green           1.861947\n",
       "change          1.601500\n",
       "world           1.576961\n",
       "waste           1.550937\n",
       "environmental   1.521280"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.DataFrame(pd.Series(gs.best_estimator_.named_steps['log'].coef_[0], index = gs.best_estimator_.named_steps['cvec'].get_feature_names()).sort_values(ascending = False)).head(10)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3c4fa-4746-4705-bb87-10315a89c4f4",
   "metadata": {},
   "source": [
    "The first data frame is showing which features/tokens had the greatest effect on the model. Most of these words would make most humans, myself included, think \"Sustainable\" before thinking \"Academia\" which would also lead to why the model does better at predicting the sustainability subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9681aeb4-1089-48c8-8d04-a111ff5a0d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>publication</th>\n",
       "      <td>-1.485804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>-1.564991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science</th>\n",
       "      <td>-1.613598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professor</th>\n",
       "      <td>-1.808880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>journal</th>\n",
       "      <td>-1.879099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postdoc</th>\n",
       "      <td>-1.885779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>-2.010196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>academic</th>\n",
       "      <td>-2.312097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phd</th>\n",
       "      <td>-2.635659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>academia</th>\n",
       "      <td>-2.727214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "publication -1.485804\n",
       "article     -1.564991\n",
       "science     -1.613598\n",
       "professor   -1.808880\n",
       "journal     -1.879099\n",
       "postdoc     -1.885779\n",
       "research    -2.010196\n",
       "academic    -2.312097\n",
       "phd         -2.635659\n",
       "academia    -2.727214"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.DataFrame(pd.Series(gs.best_estimator_.named_steps['log'].coef_[0], index = gs.best_estimator_.named_steps['cvec'].get_feature_names()).sort_values(ascending = False)).tail(10)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345383d-453d-4d03-9d2a-7c653f6266df",
   "metadata": {},
   "source": [
    "# second df. words that turned it off from sust. (positive class). makes complete sense to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54af0ecd-d887-4f1c-9775-600e4d801973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347     For those of you who switched to a bidet, was ...\n",
       "1083    Who owns the algorithms? Netflix staff protest...\n",
       "955     FlyZero: Liquid Hydrogen-Powered Plane Receive...\n",
       "629     Deets On the January 6th Insurrection Anniversary\n",
       "1026                  Stressed about Latex Gloves at Work\n",
       "                              ...                        \n",
       "1007                                    Chicagoland Peeps\n",
       "454            Scientific Journal Megathread - by subject\n",
       "664                   Do everyone a favor: run for office\n",
       "677     What would you do if you'd 50 million dollars,...\n",
       "340                   We need to do something about this!\n",
       "Name: title, Length: 92, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[y_test != preds] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f103a62-d514-4e6d-907c-1428f0ca72ac",
   "metadata": {},
   "source": [
    "#### The dataframe below shows the feature, title in this model, the subreddit the post actually belonged to and where it was predicted to belong to, the probability the logistic regression model calculated to determine which subreddit the post belonged to, and the margin of unsureness represented in the difference of the two probabilities. This data frame is the correct and icncorrect predictions of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ec69a1-28b5-4b90-880d-359d63168d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>P(r/Academia)</th>\n",
       "      <th>P(r/Sustainability)</th>\n",
       "      <th>Prob Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>Grad international students in new country</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714309</td>\n",
       "      <td>0.285691</td>\n",
       "      <td>0.428618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Solarpunk: The Power of an Aesthetic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.287701</td>\n",
       "      <td>0.712299</td>\n",
       "      <td>0.424599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>Revisiting: Balancing Author Satisfaction with...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860815</td>\n",
       "      <td>0.139185</td>\n",
       "      <td>0.721630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Clean Water... 4Earth</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099835</td>\n",
       "      <td>0.900165</td>\n",
       "      <td>0.800331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>Paying for co-authorship</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747530</td>\n",
       "      <td>0.252470</td>\n",
       "      <td>0.495060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>Don’t you just enjoy when predatory journals s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900494</td>\n",
       "      <td>0.099506</td>\n",
       "      <td>0.800989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Example of Retrospective chart review protocol...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817201</td>\n",
       "      <td>0.182799</td>\n",
       "      <td>0.634403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>Publishing A Paper? Here are 7 Types Of Peer R...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976604</td>\n",
       "      <td>0.023396</td>\n",
       "      <td>0.953207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>How do you find good research partnerships in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906982</td>\n",
       "      <td>0.093018</td>\n",
       "      <td>0.813964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>What is Academic Writing — Everything You Need...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982123</td>\n",
       "      <td>0.017877</td>\n",
       "      <td>0.964247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  actual  predicted  \\\n",
       "3808         Grad international students in new country       0          0   \n",
       "494                Solarpunk: The Power of an Aesthetic       1          1   \n",
       "3765  Revisiting: Balancing Author Satisfaction with...       0          0   \n",
       "1181                              Clean Water... 4Earth       1          1   \n",
       "2287                           Paying for co-authorship       0          0   \n",
       "...                                                 ...     ...        ...   \n",
       "2695  Don’t you just enjoy when predatory journals s...       0          0   \n",
       "1971  Example of Retrospective chart review protocol...       0          0   \n",
       "3623  Publishing A Paper? Here are 7 Types Of Peer R...       0          0   \n",
       "2068  How do you find good research partnerships in ...       0          0   \n",
       "3735  What is Academic Writing — Everything You Need...       0          0   \n",
       "\n",
       "      P(r/Academia)  P(r/Sustainability)  Prob Diff  \n",
       "3808       0.714309             0.285691   0.428618  \n",
       "494        0.287701             0.712299   0.424599  \n",
       "3765       0.860815             0.139185   0.721630  \n",
       "1181       0.099835             0.900165   0.800331  \n",
       "2287       0.747530             0.252470   0.495060  \n",
       "...             ...                  ...        ...  \n",
       "2695       0.900494             0.099506   0.800989  \n",
       "1971       0.817201             0.182799   0.634403  \n",
       "3623       0.976604             0.023396   0.953207  \n",
       "2068       0.906982             0.093018   0.813964  \n",
       "3735       0.982123             0.017877   0.964247  \n",
       "\n",
       "[992 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame({\n",
    "    'title' : X_test, \n",
    "    'actual' : y_test, \n",
    "    'predicted' : gs.predict(X_test),\n",
    "    'P(r/Academia)' : [i[0] for i in gs.predict_proba(X_test)],\n",
    "    'P(r/Sustainability)' : [i[1] for i in gs.predict_proba(X_test)]})\n",
    "preds_df['Prob Diff'] = np.abs(preds_df['P(r/Sustainability)'] - preds_df['P(r/Academia)'])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed62de-b1a9-47cc-b496-26cc27479322",
   "metadata": {},
   "source": [
    "#### The dataframe below shows the feature, title_text, the subreddit the post actually belonged to and where it was predicted to belong to, the probability the logistic regression model calculated to determine which subreddit the post belonged to, and the margin of unsureness represented in the difference of the two probabilities. This data frame is only the incorrect predictions of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c428cd89-9e37-439b-b272-a50fd86c47a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>P(r/Academia)</th>\n",
       "      <th>P(r/Sustainability)</th>\n",
       "      <th>Prob Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Stressed about Latex Gloves at Work</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.822107</td>\n",
       "      <td>0.177893</td>\n",
       "      <td>0.644213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>[Newsletter Update] They tryna cut our lights out like we don't live here - an article about purchasing practices in the apparel industry</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.766075</td>\n",
       "      <td>0.233925</td>\n",
       "      <td>0.532150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>Let's change the culture!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229203</td>\n",
       "      <td>0.770797</td>\n",
       "      <td>0.541594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>Indigenous sidlined on how to handle climate change at COP26 | Academia prefers to preach to the choir, always with their back to the congregation for a sermon that'd rather not start</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050985</td>\n",
       "      <td>0.949015</td>\n",
       "      <td>0.898030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>I work in natural resources conservation. Our office manager ordered stamps. Before this, they ALWAYS came as loose sheets inside a paper envelope. This time they’re like this. That they’re Earth Day stamps makes it even worse.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776037</td>\n",
       "      <td>0.223963</td>\n",
       "      <td>0.552073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                    title  \\\n",
       "1026                                                                                                                                                                                                  Stressed about Latex Gloves at Work   \n",
       "344                                                                                             [Newsletter Update] They tryna cut our lights out like we don't live here - an article about purchasing practices in the apparel industry   \n",
       "3380                                                                                                                                                                                                            Let's change the culture!   \n",
       "2899                                              Indigenous sidlined on how to handle climate change at COP26 | Academia prefers to preach to the choir, always with their back to the congregation for a sermon that'd rather not start   \n",
       "197   I work in natural resources conservation. Our office manager ordered stamps. Before this, they ALWAYS came as loose sheets inside a paper envelope. This time they’re like this. That they’re Earth Day stamps makes it even worse.   \n",
       "\n",
       "      actual  predicted  P(r/Academia)  P(r/Sustainability)  Prob Diff  \n",
       "1026       1          0       0.822107             0.177893   0.644213  \n",
       "344        1          0       0.766075             0.233925   0.532150  \n",
       "3380       0          1       0.229203             0.770797   0.541594  \n",
       "2899       0          1       0.050985             0.949015   0.898030  \n",
       "197        1          0       0.776037             0.223963   0.552073  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "wrong_preds_df = preds_df[preds_df['actual']!=preds_df['predicted']]\n",
    "very_wrong_preds_df = wrong_preds_df[wrong_preds_df['Prob Diff']>0.5]\n",
    "very_wrong_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18056a21-a257-4da5-8cf6-82406750fe07",
   "metadata": {},
   "source": [
    "#### The below dataframe sorts the previous dataframe with the first posts being the ones the model felt most sure about, but was wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f034cc-333f-4e19-b10d-8f1aa1839e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>P(r/Academia)</th>\n",
       "      <th>P(r/Sustainability)</th>\n",
       "      <th>Prob Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>10 second video for climate change project</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020019</td>\n",
       "      <td>0.979981</td>\n",
       "      <td>0.959962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>Computer science college student interested in volunteering</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959817</td>\n",
       "      <td>0.040183</td>\n",
       "      <td>0.919634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Scientific Journal Megathread - by subject</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.958059</td>\n",
       "      <td>0.041941</td>\n",
       "      <td>0.916118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>Indigenous sidlined on how to handle climate change at COP26 | Academia prefers to preach to the choir, always with their back to the congregation for a sermon that'd rather not start</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050985</td>\n",
       "      <td>0.949015</td>\n",
       "      <td>0.898030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>Free online magazine of possible interest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894148</td>\n",
       "      <td>0.105852</td>\n",
       "      <td>0.788297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                        title  \\\n",
       "2175                                                                                                                                               10 second video for climate change project   \n",
       "1622                                                                                                                              Computer science college student interested in volunteering   \n",
       "454                                                                                                                                                Scientific Journal Megathread - by subject   \n",
       "2899  Indigenous sidlined on how to handle climate change at COP26 | Academia prefers to preach to the choir, always with their back to the congregation for a sermon that'd rather not start   \n",
       "1784                                                                                                                                             Free online magazine of possible interest...   \n",
       "\n",
       "      actual  predicted  P(r/Academia)  P(r/Sustainability)  Prob Diff  \n",
       "2175       0          1       0.020019             0.979981   0.959962  \n",
       "1622       1          0       0.959817             0.040183   0.919634  \n",
       "454        1          0       0.958059             0.041941   0.916118  \n",
       "2899       0          1       0.050985             0.949015   0.898030  \n",
       "1784       1          0       0.894148             0.105852   0.788297  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_preds_df.sort_values(by='Prob Diff', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a4651c-278e-4ff1-9324-5b2dc1f0090a",
   "metadata": {},
   "source": [
    "## Evaluations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21e785-1ff6-43ef-9e38-1945b42645c0",
   "metadata": {},
   "source": [
    "This model is performing well, but to further answer my question which involves exploring the misclassifications, I believe I can create a model that is more accurate and will provide more concrete paths to understanding why posts are being misclassified, in hopes that it's because the language between the posts are too similar meaning there _is_ conversation about sustainability happening within academia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92e9881-faa0-401e-b877-05e5432d63f4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
